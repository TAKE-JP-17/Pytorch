{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vrfn2M8iWFOdqGoJ653QPYcyyzMLrNqe",
      "authorship_tag": "ABX9TyO2KBXf0UnA0LXApCR6CICv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAKE-JP-17/Pytorch/blob/main/flood_segmentation_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flooded area segmentation using attention unet"
      ],
      "metadata": {
        "id": "XJA-I9Qh_nJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and dataset**"
      ],
      "metadata": {
        "id": "LcmYGoaq_uDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Activation, UpSampling2D, BatchNormalization, Lambda, multiply, add\n"
      ],
      "metadata": {
        "id": "nrfpflzu_thH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KslP_oHs_j2G"
      },
      "outputs": [],
      "source": [
        "images = sorted(glob.glob('/content/drive/MyDrive/archive/Image/*.jpg'))\n",
        "masks = sorted(glob.glob('/content/drive/MyDrive/archive/Mask/*.png'))\n",
        "len(images), len(masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom data generator**"
      ],
      "metadata": {
        "id": "AUuCXgNAANEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 # 用來導入 OpenCV 模塊的指令，使得我們可以使用 OpenCV 提供的各種函數來處理圖像和視頻。讓我們可以使用 OpenCV 的功能來讀取、顯示、修改圖像，或者進行更複雜的操作，如物體檢測和圖像分割。\n",
        "import os\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_img, test_img, train_mask, test_mask = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# CustomDataGenerator class\n",
        "class CustomDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, images, masks, batch_size=8, img_size=(512, 512), shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.images = images #os.listdir(image_folder)\n",
        "        self.masks = masks #os.listdir(mask_folder)\n",
        "\n",
        "        # on each epoch end, shuffle the dataset\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # datagen(資料庫/資料來源) function to augment the input image and mask pair\n",
        "        self.datagen = ImageDataGenerator(\n",
        "            rotation_range=5,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            zoom_range=0.05,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode = 'constant',\n",
        "            cval=0.0,\n",
        "        )\n",
        "\n",
        "    # randomly crop the images to 512x512 size\n",
        "    def random_crop(self, image, mask, crop_size=512):\n",
        "\n",
        "        # image width and height calculation\n",
        "        img_height, img_width = image.shape[0], image.shape[1]\n",
        "        mask_height, mask_width = mask.shape[0], mask.shape[1]\n",
        "\n",
        "        # random x and y coordinate for cropping the image\n",
        "        x = np.random.randint(0, img_width - crop_size)\n",
        "        y = np.random.randint(0, img_height - crop_size)\n",
        "\n",
        "        # random crop\n",
        "        image_crop = image[y:y + crop_size, x:x + crop_size, :]\n",
        "        mask_crop = mask[y:y + crop_size, x:x + crop_size]\n",
        "\n",
        "        return image_crop, mask_crop\n",
        "\n",
        "    # data augmentation using keras ImageDataGenerator function\n",
        "    def data_augmentation(self, image, mask):\n",
        "        trans_param = self.datagen.get_random_transform(image.shape)\n",
        "        image = self.datagen.apply_transform(image, trans_param)\n",
        "        mask = self.datagen.apply_transform(mask, trans_param)\n",
        "        return image, mask\n",
        "\n",
        "    # length of the processing batch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    # data normalization\n",
        "    def data_normalization(self, image, mask):\n",
        "\n",
        "        # reshape mask from 512x512 to 512x512x1\n",
        "        mask = mask.reshape((*self.img_size, 1))\n",
        "\n",
        "        # Binary mask\n",
        "        mask = np.where(mask<127, 0, 1)\n",
        "\n",
        "        # data normalization (If you want to normalize another way, change the below line)\n",
        "        image = image / 255.0\n",
        "\n",
        "        # return image and mask\n",
        "        return image, mask\n",
        "\n",
        "    # data preprocessing, resize, crop image etc\n",
        "    def data_preprocessing(self, image, mask):\n",
        "        image, mask = cv2.resize(image, (576, 576)), cv2.resize(mask, (576, 576))\n",
        "        image, mask = self.random_crop(image, mask)\n",
        "        return image, mask\n",
        "\n",
        "    # on each epoch, shuffle the dataset (image and mask index)\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    # get item is the core function\n",
        "    # this function will run in each batch/epoch to load the dataset into RAM and pass to DL model\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # start and end index\n",
        "        # the last index can be shorter than the number of batches\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, len(self.images))\n",
        "        indexes = self.indexes[start_idx:end_idx]\n",
        "\n",
        "        # initialize the images and mask batches\n",
        "        batch_images = []\n",
        "        batch_masks = []\n",
        "\n",
        "        # iterate over each indexes in batch\n",
        "        for i in indexes:\n",
        "            img_path = self.images[i]\n",
        "            mask_path = self.masks[i]\n",
        "\n",
        "            # read image using open cv\n",
        "            img = cv2.imread(img_path)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Skip if image or mask is not loaded properly\n",
        "            if img is None or mask is None:\n",
        "                continue\n",
        "\n",
        "            # image preprocessing; resize, random crop\n",
        "            img, mask = self.data_preprocessing(img, mask)\n",
        "\n",
        "            # data normalization\n",
        "            img, mask = self.data_normalization(img, mask)\n",
        "\n",
        "            # data augmentation\n",
        "            img, mask = self.data_augmentation(img, mask)\n",
        "\n",
        "            # to fix the issue during training process\n",
        "            mask = mask.astype(np.float32)\n",
        "\n",
        "            # append each image, mask pair to the batches\n",
        "            batch_images.append(img)\n",
        "            batch_masks.append(mask)\n",
        "\n",
        "        # return batch image and batch mamks as a numpy array (n, tile_x, tile_y, channels)\n",
        "        return np.array(batch_images), np.array(batch_masks)"
      ],
      "metadata": {
        "id": "zT-zGwy_AIFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing and visualization of image/mask pair**"
      ],
      "metadata": {
        "id": "2w8kEORaAVbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = CustomDataGenerator(images, masks)\n",
        "batch_images, batch_masks = data.__getitem__(0)\n",
        "\n",
        "img = np.random.randint(0,8)\n",
        "# Visualize the first image and its mask from the batch\n",
        "image = batch_images[img]\n",
        "mask = batch_masks[img]\n",
        "\n",
        "# Plotting the image and its mask\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Display Image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display Mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.title('Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cb8HGoqRAS0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the generators\n",
        "train_dataset = CustomDataGenerator(train_img, train_mask)\n",
        "test_dataset = CustomDataGenerator(test_img, test_mask)"
      ],
      "metadata": {
        "id": "XhbbutuxUQGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test dataset split**"
      ],
      "metadata": {
        "id": "ARTI3K56Ad09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_img, test_img, train_mask, test_mask = train_test_split(images, masks, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CPDomp-PAZ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_img), len(test_img)"
      ],
      "metadata": {
        "id": "cL6j_VO8AmSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataGenerator(train_img, train_mask)\n",
        "test_dataset = CustomDataGenerator(test_img, test_mask)"
      ],
      "metadata": {
        "id": "Oo2MQuBFAocA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "By45PV99AqY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom metrics**\n",
        "\n",
        "\n",
        "1.   Precision\n",
        "2.   Recall\n",
        "3.   F1-Score\n",
        "4.   Dice loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UCyFAj-nAwbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom loss function**"
      ],
      "metadata": {
        "id": "yLw7lEnwBH7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# recall\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# precision\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "#f1 score\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aF9VMr9QAsOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention unet**"
      ],
      "metadata": {
        "id": "fhDh51TYBuqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "# from utils.utils import f1_m, precision_m, recall_m, dsc\n",
        "\n",
        "from sklearn.metrics import *\n",
        "\n",
        "def expend_as(tensor, rep,name):\n",
        "\tmy_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': rep},  name='psi_up'+name)(tensor)\n",
        "\treturn my_repeat\n",
        "\n",
        "\n",
        "def AttnGatingBlock(x, g, inter_shape, name):\n",
        "    ''' take g which is the spatially smaller signal, do a conv to get the same\n",
        "    number of feature channels as x (bigger spatially)\n",
        "    do a conv on x to also get same geature channels (theta_x)\n",
        "    then, upsample g to be same size as x\n",
        "    add x and g (concat_xg)\n",
        "    relu, 1x1 conv, then sigmoid then upsample the final - this gives us attn coefficients'''\n",
        "\n",
        "    shape_x = K.int_shape(x)  # 32\n",
        "    shape_g = K.int_shape(g)  # 16\n",
        "\n",
        "    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', name='xl'+name)(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)\n",
        "    upsample_g = Conv2DTranspose(inter_shape, (3, 3),strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),padding='same', name='g_up'+name)(phi_g)  # 16\n",
        "\n",
        "    concat_xg = add([upsample_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "    psi = Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    # upsample_psi = expend_as(upsample_psi, shape_x[3],  name)\n",
        "    y = multiply([upsample_psi, x], name='q_attn'+name)\n",
        "\n",
        "    result = Conv2D(shape_x[3], (1, 1), padding='same',name='q_attn_conv'+name)(y)\n",
        "    result_bn = BatchNormalization(name='q_attn_bn'+name)(result)\n",
        "    return result_bn\n",
        "\n",
        "def UnetConv2D(input, outdim, is_batchnorm, name):\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "\tif is_batchnorm:\n",
        "\t\tx =BatchNormalization(name=name + '_1_bn')(x)\n",
        "\tx = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "\tif is_batchnorm:\n",
        "\t\tx = BatchNormalization(name=name + '_2_bn')(x)\n",
        "\tx = Activation('relu', name=name + '_2_act')(x)\n",
        "\treturn x\n"
      ],
      "metadata": {
        "id": "3h8rFihsBNfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UnetGatingSignal(input, is_batchnorm, name):\n",
        "    ''' this is simply 1x1 convolution, bn, activation '''\n",
        "    shape = K.int_shape(input)\n",
        "    x = Conv2D(shape[3] * 1, (1, 1), strides=(1, 1), padding=\"same\",  kernel_initializer=kinit, name=name + '_conv')(input)\n",
        "    if is_batchnorm:\n",
        "        x = BatchNormalization(name=name + '_bn')(x)\n",
        "    x = Activation('relu', name = name + '_act')(x)\n",
        "    return x\n",
        "\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "kinit = 'glorot_normal'\n",
        "\n",
        "def attn_unet(lr, loss_func=None, pretrained_weights = None, input_size = (256, 256, 6)):\n",
        "        inputs = Input(shape=input_size)\n",
        "\n",
        "        #Contraction path\n",
        "        conv1 = UnetConv2D(inputs, 64, is_batchnorm=True, name='conv1')\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "        conv2 = UnetConv2D(pool1, 64, is_batchnorm=True, name='conv2')\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "        conv3 = UnetConv2D(pool2, 128, is_batchnorm=True, name='conv3')\n",
        "        conv3 = Dropout(0.1,name='drop_conv3')(conv3)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "        conv4 = UnetConv2D(pool3, 128, is_batchnorm=True, name='conv4')\n",
        "        # conv4 = Dropout(0.2, name='drop_conv4')(conv4)\n",
        "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "        conv5 = UnetConv2D(pool4, 256, is_batchnorm=True, name='conv5')\n",
        "        # conv5 = Dropout(0.2,name='drop_conv5')(conv5)\n",
        "        pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
        "\n",
        "        conv6 = UnetConv2D(pool5, 256, is_batchnorm=True, name='conv6')\n",
        "        # conv6 = Dropout(0.2, name='drop_conv6')(conv6)\n",
        "        pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
        "\n",
        "        #center layer\n",
        "        center = UnetConv2D(pool6, 512, is_batchnorm=True, name='center')\n",
        "\n",
        "        # Expansion path\n",
        "        g1 = UnetGatingSignal(center, is_batchnorm=True, name='g1')\n",
        "        attn1 = AttnGatingBlock(conv6, g1, 512, '_1')\n",
        "        # attn1 = Dropout(0.2, name='drop_attn1')(attn1)\n",
        "        convt1 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt1')(center)\n",
        "        up1 = concatenate([convt1, attn1], name='up1')\n",
        "\n",
        "        g2 = UnetGatingSignal(up1, is_batchnorm=True, name='g2')\n",
        "        attn2 = AttnGatingBlock(conv5, g2, 256, '_2')\n",
        "        # attn2 = Dropout(0.2, name='drop_attn2')(attn2)\n",
        "        convt2 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt2')(up1)\n",
        "        up2 = concatenate([convt2, attn2], name='up2')\n",
        "\n",
        "        g3 = UnetGatingSignal(up2, is_batchnorm=True, name='g3')\n",
        "        attn3 = AttnGatingBlock(conv4, g3, 128, '_3')\n",
        "        # attn3 = Dropout(0.2, name='drop_attn3')(attn3)\n",
        "        convt3 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt3')(up2)\n",
        "        up3 = concatenate([convt3, attn3], name='up3')\n",
        "\n",
        "        g4 = UnetGatingSignal(up3, is_batchnorm=True, name='g4')\n",
        "        attn4 = AttnGatingBlock(conv3, g4, 128, '_4')\n",
        "        # attn4 = Dropout(0.2, name='drop_attn4')(attn4)\n",
        "        convt4 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt4')(up3)\n",
        "        up4 = concatenate([convt4, attn4], name='up4')\n",
        "\n",
        "        g5 = UnetGatingSignal(up4, is_batchnorm=True, name='g5')\n",
        "        attn5 = AttnGatingBlock(conv2, g5, 64, '_5')\n",
        "        attn5 = Dropout(0.2, name='drop_attn5')(attn5)\n",
        "        convt5 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt5')(up4)\n",
        "        up5 = concatenate([convt5, attn5], name='up5')\n",
        "\n",
        "        convt6 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt6')(up5)\n",
        "        up6 = concatenate([convt6, conv1], name='up6')\n",
        "        conv10 = Conv2D(1, (1, 1), activation='sigmoid',  kernel_initializer=kinit, name='final')(up6)\n",
        "\n",
        "        model = Model(inputs, conv10)\n",
        "\n",
        "        # compile model\n",
        "        model.compile(optimizer = Adam(learning_rate=lr), loss = loss_func, metrics = ['accuracy', f1_m, precision_m, recall_m, dsc])\n",
        "\n",
        "        if(pretrained_weights):\n",
        "            model.load_weights(pretrained_weights)\n",
        "\n",
        "        return model\n",
        "# Compile the model\n",
        "model = attn_unet(0.001, loss_func='binary_crossentropy',input_size=(512,512,3))\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "U53nh1sKGhKa"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training model**"
      ],
      "metadata": {
        "id": "vjLMpm7ZC0MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# callback functions\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(f\"/content/drive/MyDrive/dl/flood/flood_best.h5\", monitor=\"val_f1_m\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', patience=5, verbose=1, mode='max')\n",
        "\n",
        "callbacks = [\n",
        "    earlyStopping,\n",
        "    checkpointer\n",
        "    ]\n",
        "\n",
        "# model training\n",
        "history = model.fit(train_dataset,epochs=50,\n",
        "                    verbose = 1,\n",
        "                    # validation_split=0.15,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# save the model weights at the end of the training process\n",
        "model.save(f\"/content/drive/MyDrive/dl/flood/flood_save.h5\")"
      ],
      "metadata": {
        "id": "948pJ2UzChTC",
        "outputId": "2128c02d-ab7a-411f-ad27-8ec273603f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model performance**"
      ],
      "metadata": {
        "id": "R_HcmwX3C8Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,((ax11, ax12),(ax13,ax14)) = plt.subplots(2,2,figsize=(10,10))\n",
        "ax11.plot(history.history['loss'])\n",
        "ax11.plot(history.history['val_loss'])\n",
        "ax11.title.set_text('Unet model loss')\n",
        "ax11.set_ylabel('loss')\n",
        "ax11.set_xlabel('epoch')\n",
        "ax11.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax12.plot(history.history['precision_m'])\n",
        "ax12.plot(history.history['val_precision_m'])\n",
        "ax12.set_title('Unet model precision')\n",
        "ax12.set_ylabel('precision')\n",
        "ax12.set_xlabel('epoch')\n",
        "ax12.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax13.plot(history.history['recall_m'])\n",
        "ax13.plot(history.history['val_recall_m'])\n",
        "ax13.set_title('Unet model recall')\n",
        "ax13.set_ylabel('recall')\n",
        "ax13.set_xlabel('epoch')\n",
        "ax13.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax14.plot(history.history['f1_m'])\n",
        "ax14.plot(history.history['val_f1_m'])\n",
        "ax14.set_title('Unet model f1')\n",
        "ax14.set_ylabel('f1')\n",
        "ax14.set_xlabel('epoch')\n",
        "ax14.legend(['train', 'validation'], loc='upper left')"
      ],
      "metadata": {
        "id": "YldJslxOC-Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load best model**"
      ],
      "metadata": {
        "id": "dPpLGfFHDDOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Define the custom loss function before loading the model\n",
        "custom_objects = {\"f1_m\": f1_m, 'precision_m': precision_m, 'recall_m': recall_m, 'dsc': dsc}\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/dl/flood/flood_best.h5', custom_objects=custom_objects)\n",
        "\n",
        "# pred"
      ],
      "metadata": {
        "id": "7dTQRqDrDFCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy, f1_score, precision, recall, dsc = model.evaluate(test_dataset, verbose=0)\n",
        "loss, accuracy, f1_score, precision, recall, dsc = model.evaluate(test_dataset, verbose=0)\n",
        "print(loss, accuracy, f1_score, precision, recall, dsc)"
      ],
      "metadata": {
        "id": "cJD9xmG0DHAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction on custom images**"
      ],
      "metadata": {
        "id": "z4aBNnVEDK9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "imgs = glob.glob('/content/*.jpg')\n",
        "\n",
        "img_test = np.zeros((3, 512, 512, 3))\n",
        "for index, i in enumerate(imgs):\n",
        "  img = cv2.imread(i)\n",
        "  img = cv2.resize(img, (512, 512))\n",
        "  img = img / 255.0\n",
        "  # print(img.shape)\n",
        "  img_test[index] = img"
      ],
      "metadata": {
        "id": "mpCxaXvsDMUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(img_test)\n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "pred.shape"
      ],
      "metadata": {
        "id": "KZDZiGMXDN4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(axes)= plt.subplots(3, 2, figsize=(12,12))\n",
        "\n",
        "for i in range(3):\n",
        "    # Load and display the original image\n",
        "    axes[i, 0].imshow(img_test[i])\n",
        "    axes[i, 0].set_title(f'Image {i+1}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Load and display the corresponding prediction\n",
        "    axes[i, 1].imshow(pred[i])\n",
        "    axes[i, 1].set_title(f'Prediction {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "5QrzAk_ADQl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}