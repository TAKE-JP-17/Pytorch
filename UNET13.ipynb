{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMooOT+7yzg9Tky+APTCu70",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAKE-JP-17/Pytorch/blob/main/UNET13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFQ9vZajoz1N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = sorted(glob.glob('/content/drive/MyDrive/archive/Image/*.jpg'))\n",
        "masks = sorted(glob.glob('/content/drive/MyDrive/archive/Mask/*.png'))\n",
        "len(images), len(masks)"
      ],
      "metadata": {
        "id": "iRxjKMRfo5xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 # 用來導入 OpenCV 模塊的指令，使得我們可以使用 OpenCV 提供的各種函數來處理圖像和視頻。讓我們可以使用 OpenCV 的功能來讀取、顯示、修改圖像，或者進行更複雜的操作，如物體檢測和圖像分割。\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class CustomDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, images, masks, batch_size=8, img_size=(512, 512), shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.images = images #os.listdir(image_folder)\n",
        "        self.masks = masks #os.listdir(mask_folder)\n",
        "\n",
        "        # on each epoch end, shuffle the dataset\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # datagen(資料庫/資料來源) function to augment the input image and mask pair\n",
        "        self.datagen = ImageDataGenerator(\n",
        "            rotation_range=5,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            zoom_range=0.05,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode = 'constant',\n",
        "            cval=0.0,\n",
        "        )\n",
        "\n",
        "    # randomly crop the images to 512x512 size\n",
        "    def random_crop(self, image, mask, crop_size=512):\n",
        "\n",
        "        # image width and height calculation\n",
        "        img_height, img_width = image.shape[0], image.shape[1]\n",
        "        mask_height, mask_width = mask.shape[0], mask.shape[1]\n",
        "\n",
        "        # random x and y coordinate for cropping the image\n",
        "        x = np.random.randint(0, img_width - crop_size)\n",
        "        y = np.random.randint(0, img_height - crop_size)\n",
        "\n",
        "        # random crop\n",
        "        image_crop = image[y:y + crop_size, x:x + crop_size, :]\n",
        "        mask_crop = mask[y:y + crop_size, x:x + crop_size]\n",
        "\n",
        "        return image_crop, mask_crop\n",
        "\n",
        "    # data augmentation using keras ImageDataGenerator function\n",
        "    def data_augmentation(self, image, mask):\n",
        "        trans_param = self.datagen.get_random_transform(image.shape)\n",
        "        image = self.datagen.apply_transform(image, trans_param)\n",
        "        mask = self.datagen.apply_transform(mask, trans_param)\n",
        "        return image, mask\n",
        "\n",
        "    # length of the processing batch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    # data normalization\n",
        "    def data_normalization(self, image, mask):\n",
        "\n",
        "        # reshape mask from 512x512 to 512x512x1\n",
        "        mask = mask.reshape((*self.img_size, 1))\n",
        "\n",
        "        # Binary mask\n",
        "        mask = np.where(mask<127, 0, 1)\n",
        "\n",
        "        # data normalization (If you want to normalize another way, change the below line)\n",
        "        image = image / 255.0\n",
        "\n",
        "        # return image and mask\n",
        "        return image, mask\n",
        "\n",
        "    # data preprocessing, resize, crop image etc\n",
        "    def data_preprocessing(self, image, mask):\n",
        "        image, mask = cv2.resize(image, (576, 576)), cv2.resize(mask, (576, 576))\n",
        "        image, mask = self.random_crop(image, mask)\n",
        "        return image, mask\n",
        "\n",
        "    # on each epoch, shuffle the dataset (image and mask index)\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    # get item is the core function\n",
        "    # this function will run in each batch/epoch to load the dataset into RAM and pass to DL model\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # start and end index\n",
        "        # the last index can be shorter than the number of batches\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, len(self.images))\n",
        "        indexes = self.indexes[start_idx:end_idx]\n",
        "\n",
        "        # initialize the images and mask batches\n",
        "        batch_images = []\n",
        "        batch_masks = []\n",
        "\n",
        "        # iterate over each indexes in batch\n",
        "        for i in indexes:\n",
        "            img_path = self.images[i]\n",
        "            mask_path = self.masks[i]\n",
        "\n",
        "            # read image using open cv\n",
        "            img = cv2.imread(img_path)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Skip if image or mask is not loaded properly\n",
        "            if img is None or mask is None:\n",
        "                continue\n",
        "\n",
        "            # image preprocessing; resize, random crop\n",
        "            img, mask = self.data_preprocessing(img, mask)\n",
        "\n",
        "            # data normalization\n",
        "            img, mask = self.data_normalization(img, mask)\n",
        "\n",
        "            # data augmentation\n",
        "            img, mask = self.data_augmentation(img, mask)\n",
        "\n",
        "            # to fix the issue during training process\n",
        "            mask = mask.astype(np.float32)\n",
        "\n",
        "            # append each image, mask pair to the batches\n",
        "            batch_images.append(img)\n",
        "            batch_masks.append(mask)\n",
        "\n",
        "        # return batch image and batch mamks as a numpy array (n, tile_x, tile_y, channels)\n",
        "        return np.array(batch_images), np.array(batch_masks)"
      ],
      "metadata": {
        "id": "ZhL1QWwno7wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = CustomDataGenerator(images, masks)\n",
        "batch_images, batch_masks = data.__getitem__(0)\n",
        "\n",
        "img = np.random.randint(0,8)\n",
        "# Visualize the first image and its mask from the batch\n",
        "image = batch_images[img]\n",
        "mask = batch_masks[img]\n",
        "\n",
        "# Plotting the image and its mask\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Display Image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display Mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.title('Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ozYDB4owpCtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "\n",
        "def AttnGatingBlock(x, g, inter_shape, name):\n",
        "    ''' take g which is the spatially smaller signal, do a conv to get the same\n",
        "    number of feature channels as x (bigger spatially)\n",
        "    do a conv on x to also get same geature channels (theta_x)\n",
        "    then, upsample g to be same size as x\n",
        "    add x and g (concat_xg)\n",
        "    relu, 1x1 conv, then sigmoid then upsample the final - this gives us attn coefficients'''\n",
        "\n",
        "    shape_x = K.int_shape(x)  # 32\n",
        "    shape_g = K.int_shape(g)  # 16\n",
        "\n",
        "    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', name='xl'+name)(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)\n",
        "    upsample_g = Conv2DTranspose(inter_shape, (3, 3),strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),padding='same', name='g_up'+name)(phi_g)  # 16\n",
        "\n",
        "    concat_xg = add([upsample_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "    psi = Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    # upsample_psi = expend_as(upsample_psi, shape_x[3],  name)\n",
        "    y = multiply([upsample_psi, x], name='q_attn'+name)\n",
        "\n",
        "    result = Conv2D(shape_x[3], (1, 1), padding='same',name='q_attn_conv'+name)(y)\n",
        "    result_bn = BatchNormalization(name='q_attn_bn'+name)(result)\n",
        "    return result_bn"
      ],
      "metadata": {
        "id": "YnPjAi8ApFuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UnetConv2D(input, outdim, is_batchnorm, name):\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "\tif is_batchnorm:\n",
        "\t\tx =BatchNormalization(name=name + '_1_bn')(x)\n",
        "\tx = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "\tif is_batchnorm:\n",
        "\t\tx = BatchNormalization(name=name + '_2_bn')(x)\n",
        "\tx = Activation('relu', name=name + '_2_act')(x)\n",
        "\treturn x"
      ],
      "metadata": {
        "id": "lNKgGxtUpTyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UnetGatingSignal(input, is_batchnorm, name):\n",
        "    ''' this is simply 1x1 convolution, bn, activation '''\n",
        "    shape = K.int_shape(input)\n",
        "    x = Conv2D(shape[3] * 1, (1, 1), strides=(1, 1), padding=\"same\",  kernel_initializer=kinit, name=name + '_conv')(input)\n",
        "    if is_batchnorm:\n",
        "        x = BatchNormalization(name=name + '_bn')(x)\n",
        "    x = Activation('relu', name = name + '_act')(x)\n",
        "    return x\n",
        "\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "kinit = 'glorot_normal'\n",
        "\n",
        "def attn_unet(lr, loss_func=None, pretrained_weights = None, input_size = (256, 256, 6)):\n",
        "        inputs = Input(shape=input_size)\n",
        "\n",
        "        #Contraction path\n",
        "        conv1 = UnetConv2D(inputs, 64, is_batchnorm=True, name='conv1')\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "        conv2 = UnetConv2D(pool1, 64, is_batchnorm=True, name='conv2')\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "        conv3 = UnetConv2D(pool2, 128, is_batchnorm=True, name='conv3')\n",
        "        conv3 = Dropout(0.1,name='drop_conv3')(conv3)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "        conv4 = UnetConv2D(pool3, 128, is_batchnorm=True, name='conv4')\n",
        "        # conv4 = Dropout(0.2, name='drop_conv4')(conv4)\n",
        "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "        conv5 = UnetConv2D(pool4, 256, is_batchnorm=True, name='conv5')\n",
        "        # conv5 = Dropout(0.2,name='drop_conv5')(conv5)\n",
        "        pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
        "\n",
        "        conv6 = UnetConv2D(pool5, 256, is_batchnorm=True, name='conv6')\n",
        "        # conv6 = Dropout(0.2, name='drop_conv6')(conv6)\n",
        "        pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
        "\n",
        "        #center layer\n",
        "        center = UnetConv2D(pool6, 512, is_batchnorm=True, name='center')\n",
        "\n",
        "        # Expansion path\n",
        "        g1 = UnetGatingSignal(center, is_batchnorm=True, name='g1')\n",
        "        attn1 = AttnGatingBlock(conv6, g1, 512, '_1')\n",
        "        # attn1 = Dropout(0.2, name='drop_attn1')(attn1)\n",
        "        convt1 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt1')(center)\n",
        "        up1 = concatenate([convt1, attn1], name='up1')\n",
        "\n",
        "        g2 = UnetGatingSignal(up1, is_batchnorm=True, name='g2')\n",
        "        attn2 = AttnGatingBlock(conv5, g2, 256, '_2')\n",
        "        # attn2 = Dropout(0.2, name='drop_attn2')(attn2)\n",
        "        convt2 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt2')(up1)\n",
        "        up2 = concatenate([convt2, attn2], name='up2')\n",
        "\n",
        "        g3 = UnetGatingSignal(up2, is_batchnorm=True, name='g3')\n",
        "        attn3 = AttnGatingBlock(conv4, g3, 128, '_3')\n",
        "        # attn3 = Dropout(0.2, name='drop_attn3')(attn3)\n",
        "        convt3 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt3')(up2)\n",
        "        up3 = concatenate([convt3, attn3], name='up3')\n",
        "\n",
        "        g4 = UnetGatingSignal(up3, is_batchnorm=True, name='g4')\n",
        "        attn4 = AttnGatingBlock(conv3, g4, 128, '_4')\n",
        "        # attn4 = Dropout(0.2, name='drop_attn4')(attn4)\n",
        "        convt4 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt4')(up3)\n",
        "        up4 = concatenate([convt4, attn4], name='up4')\n",
        "\n",
        "        g5 = UnetGatingSignal(up4, is_batchnorm=True, name='g5')\n",
        "        attn5 = AttnGatingBlock(conv2, g5, 64, '_5')\n",
        "        attn5 = Dropout(0.2, name='drop_attn5')(attn5)\n",
        "        convt5 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt5')(up4)\n",
        "        up5 = concatenate([convt5, attn5], name='up5')\n",
        "\n",
        "        convt6 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt6')(up5)\n",
        "        up6 = concatenate([convt6, conv1], name='up6')\n",
        "        conv10 = Conv2D(1, (1, 1), activation='sigmoid',  kernel_initializer=kinit, name='final')(up6)\n",
        "\n",
        "        model = Model(inputs, conv10)\n",
        "\n",
        "        # compile model\n",
        "        model.compile(optimizer = Adam(learning_rate=lr), loss = loss_func, metrics = ['accuracy', f1_m, precision_m, recall_m, dsc])\n",
        "\n",
        "        if(pretrained_weights):\n",
        "            model.load_weights(pretrained_weights)\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "oMmSuAIHpWH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = attn_unet(0.001, loss_func='binary_crossentropy')"
      ],
      "metadata": {
        "id": "fq5-M9uzpdBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "bKwdGusVpfwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_img, test_img, train_mask, test_mask = train_test_split(images, masks, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "e3dvcp73ph90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_img), len(test_img)"
      ],
      "metadata": {
        "id": "MIqy-S1dph89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataGenerator(train_img, train_mask)\n",
        "test_dataset = CustomDataGenerator(test_img, test_mask)"
      ],
      "metadata": {
        "id": "Vh0fTxHMpt28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "T9kMtYO4pwHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# recall\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# precision\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "#f1 score\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "uuSFBZI3pxid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callback functions\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(f\"/content/drive/MyDrive/dl/flood/flood_best.h5\", monitor=\"val_f1_m\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', patience=5, verbose=1, mode='max')\n",
        "\n",
        "callbacks = [\n",
        "    earlyStopping,\n",
        "    checkpointer\n",
        "    ]\n",
        "\n",
        "# model training\n",
        "history = model.fit(train_dataset,epochs=50,\n",
        "                    verbose = 1,\n",
        "                    # validation_split=0.15,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# save the model weights at the end of the training process\n",
        "model.save(f\"/content/drive/MyDrive/dl/flood/flood_save.h5\")"
      ],
      "metadata": {
        "id": "cQYjSBNRp_mi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}