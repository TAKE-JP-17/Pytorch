{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/TAKE-JP-17/Pytorch/blob/main/flood_segmentation_v1.ipynb",
      "authorship_tag": "ABX9TyMaU0C0AgbuQ5dR4ThxHiDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAKE-JP-17/Pytorch/blob/main/flood_segmentation_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y"
      ],
      "metadata": {
        "id": "dpFXXng6sxgy",
        "outputId": "2b02a615-ef58-4394-d0a7-f86dc8c0c094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.0\n",
            "Uninstalling tensorflow-2.17.0:\n",
            "  Successfully uninstalled tensorflow-2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.1"
      ],
      "metadata": {
        "id": "QSakB2patNfh",
        "outputId": "785e9b1c-b0dc-474e-c6ae-fbd8ff8daba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.11.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (24.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
            "Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.66.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.26.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "e9af042413f24945923b2164f806b9b3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "ThSR1XzTtOYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "j10YUwO0tRnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flooded area segmentation using attention unet"
      ],
      "metadata": {
        "id": "XJA-I9Qh_nJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and dataset**"
      ],
      "metadata": {
        "id": "LcmYGoaq_uDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Activation, UpSampling2D, BatchNormalization, Lambda, multiply, add\n"
      ],
      "metadata": {
        "id": "nrfpflzu_thH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KslP_oHs_j2G"
      },
      "outputs": [],
      "source": [
        "images = sorted(glob.glob('/content/drive/MyDrive/archive/Image/*.jpg'))\n",
        "masks = sorted(glob.glob('/content/drive/MyDrive/archive/Mask/*.png'))\n",
        "len(images), len(masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom data generator**"
      ],
      "metadata": {
        "id": "AUuCXgNAANEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 # 用來導入 OpenCV 模塊的指令，使得我們可以使用 OpenCV 提供的各種函數來處理圖像和視頻。讓我們可以使用 OpenCV 的功能來讀取、顯示、修改圖像，或者進行更複雜的操作，如物體檢測和圖像分割。\n",
        "import os\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_img, test_img, train_mask, test_mask = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# CustomDataGenerator class\n",
        "class CustomDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, images, masks, batch_size=8, img_size=(512, 512), shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.images = images #os.listdir(image_folder)\n",
        "        self.masks = masks #os.listdir(mask_folder)\n",
        "\n",
        "        # on each epoch end, shuffle the dataset\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # datagen(資料庫/資料來源) function to augment the input image and mask pair\n",
        "        self.datagen = ImageDataGenerator(\n",
        "            rotation_range=5,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            zoom_range=0.05,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode = 'constant',\n",
        "            cval=0.0,\n",
        "        )\n",
        "\n",
        "    # randomly crop the images to 512x512 size\n",
        "    def random_crop(self, image, mask, crop_size=512):\n",
        "\n",
        "        # image width and height calculation\n",
        "        img_height, img_width = image.shape[0], image.shape[1]\n",
        "        mask_height, mask_width = mask.shape[0], mask.shape[1]\n",
        "\n",
        "        # random x and y coordinate for cropping the image\n",
        "        x = np.random.randint(0, img_width - crop_size)\n",
        "        y = np.random.randint(0, img_height - crop_size)\n",
        "\n",
        "        # random crop\n",
        "        image_crop = image[y:y + crop_size, x:x + crop_size, :]\n",
        "        mask_crop = mask[y:y + crop_size, x:x + crop_size]\n",
        "\n",
        "        return image_crop, mask_crop\n",
        "\n",
        "    # data augmentation using keras ImageDataGenerator function\n",
        "    def data_augmentation(self, image, mask):\n",
        "        trans_param = self.datagen.get_random_transform(image.shape)\n",
        "        image = self.datagen.apply_transform(image, trans_param)\n",
        "        mask = self.datagen.apply_transform(mask, trans_param)\n",
        "        return image, mask\n",
        "\n",
        "    # length of the processing batch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    # data normalization\n",
        "    def data_normalization(self, image, mask):\n",
        "\n",
        "        # reshape mask from 512x512 to 512x512x1\n",
        "        mask = mask.reshape((*self.img_size, 1))\n",
        "\n",
        "        # Binary mask\n",
        "        mask = np.where(mask<127, 0, 1)\n",
        "\n",
        "        # data normalization (If you want to normalize another way, change the below line)\n",
        "        image = image / 255.0\n",
        "\n",
        "        # return image and mask\n",
        "        return image, mask\n",
        "\n",
        "    # data preprocessing, resize, crop image etc\n",
        "    def data_preprocessing(self, image, mask):\n",
        "        image, mask = cv2.resize(image, (576, 576)), cv2.resize(mask, (576, 576))\n",
        "        image, mask = self.random_crop(image, mask)\n",
        "        return image, mask\n",
        "\n",
        "    # on each epoch, shuffle the dataset (image and mask index)\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    # get item is the core function\n",
        "    # this function will run in each batch/epoch to load the dataset into RAM and pass to DL model\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # start and end index\n",
        "        # the last index can be shorter than the number of batches\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, len(self.images))\n",
        "        indexes = self.indexes[start_idx:end_idx]\n",
        "\n",
        "        # initialize the images and mask batches\n",
        "        batch_images = []\n",
        "        batch_masks = []\n",
        "\n",
        "        # iterate over each indexes in batch\n",
        "        for i in indexes:\n",
        "            img_path = self.images[i]\n",
        "            mask_path = self.masks[i]\n",
        "\n",
        "            # read image using open cv\n",
        "            img = cv2.imread(img_path)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Skip if image or mask is not loaded properly\n",
        "            if img is None or mask is None:\n",
        "                continue\n",
        "\n",
        "            # image preprocessing; resize, random crop\n",
        "            img, mask = self.data_preprocessing(img, mask)\n",
        "\n",
        "            # data normalization\n",
        "            img, mask = self.data_normalization(img, mask)\n",
        "\n",
        "            # data augmentation\n",
        "            img, mask = self.data_augmentation(img, mask)\n",
        "\n",
        "            # to fix the issue during training process\n",
        "            mask = mask.astype(np.float32)\n",
        "\n",
        "            # append each image, mask pair to the batches\n",
        "            batch_images.append(img)\n",
        "            batch_masks.append(mask)\n",
        "\n",
        "        # return batch image and batch mamks as a numpy array (n, tile_x, tile_y, channels)\n",
        "        return np.array(batch_images), np.array(batch_masks)"
      ],
      "metadata": {
        "id": "zT-zGwy_AIFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing and visualization of image/mask pair**"
      ],
      "metadata": {
        "id": "2w8kEORaAVbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = CustomDataGenerator(images, masks)\n",
        "batch_images, batch_masks = data.__getitem__(0)\n",
        "\n",
        "img = np.random.randint(0,8)\n",
        "# Visualize the first image and its mask from the batch\n",
        "image = batch_images[img]\n",
        "mask = batch_masks[img]\n",
        "\n",
        "# Plotting the image and its mask\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Display Image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Display Mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.title('Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cb8HGoqRAS0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the generators\n",
        "train_dataset = CustomDataGenerator(train_img, train_mask)\n",
        "test_dataset = CustomDataGenerator(test_img, test_mask)"
      ],
      "metadata": {
        "id": "XhbbutuxUQGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test dataset split**"
      ],
      "metadata": {
        "id": "ARTI3K56Ad09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_img, test_img, train_mask, test_mask = train_test_split(images, masks, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CPDomp-PAZ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_img), len(test_img)"
      ],
      "metadata": {
        "id": "cL6j_VO8AmSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataGenerator(train_img, train_mask)\n",
        "test_dataset = CustomDataGenerator(test_img, test_mask)"
      ],
      "metadata": {
        "id": "Oo2MQuBFAocA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "By45PV99AqY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom metrics**\n",
        "\n",
        "\n",
        "1.   Precision\n",
        "2.   Recall\n",
        "3.   F1-Score\n",
        "4.   Dice loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UCyFAj-nAwbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom loss function**"
      ],
      "metadata": {
        "id": "yLw7lEnwBH7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# recall\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# precision\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "#f1 score\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aF9VMr9QAsOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention unet**"
      ],
      "metadata": {
        "id": "fhDh51TYBuqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "# from utils.utils import f1_m, precision_m, recall_m, dsc\n",
        "\n",
        "from sklearn.metrics import *\n",
        "\n",
        "def expend_as(tensor, rep,name):\n",
        "\tmy_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': rep},  name='psi_up'+name)(tensor)\n",
        "\treturn my_repeat\n",
        "\n",
        "\n",
        "def AttnGatingBlock(x, g, inter_shape, name):\n",
        "    ''' take g which is the spatially smaller signal, do a conv to get the same\n",
        "    number of feature channels as x (bigger spatially)\n",
        "    do a conv on x to also get same geature channels (theta_x)\n",
        "    then, upsample g to be same size as x\n",
        "    add x and g (concat_xg)\n",
        "    relu, 1x1 conv, then sigmoid then upsample the final - this gives us attn coefficients'''\n",
        "\n",
        "    shape_x = K.int_shape(x)  # 32\n",
        "    shape_g = K.int_shape(g)  # 16\n",
        "\n",
        "    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', name='xl'+name)(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)\n",
        "    upsample_g = Conv2DTranspose(inter_shape, (3, 3),strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),padding='same', name='g_up'+name)(phi_g)  # 16\n",
        "\n",
        "    concat_xg = add([upsample_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "    psi = Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    # upsample_psi = expend_as(upsample_psi, shape_x[3],  name)\n",
        "    y = multiply([upsample_psi, x], name='q_attn'+name)\n",
        "\n",
        "    result = Conv2D(shape_x[3], (1, 1), padding='same',name='q_attn_conv'+name)(y)\n",
        "    result_bn = BatchNormalization(name='q_attn_bn'+name)(result)\n",
        "    return result_bn\n",
        "\n",
        "def UnetConv2D(input, outdim, is_batchnorm, name):\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "\tif is_batchnorm:\n",
        "\t\tx =BatchNormalization(name=name + '_1_bn')(x)\n",
        "\tx = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "\tif is_batchnorm:\n",
        "\t\tx = BatchNormalization(name=name + '_2_bn')(x)\n",
        "\tx = Activation('relu', name=name + '_2_act')(x)\n",
        "\treturn x\n"
      ],
      "metadata": {
        "id": "3h8rFihsBNfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UnetGatingSignal(input, is_batchnorm, name):\n",
        "    ''' this is simply 1x1 convolution, bn, activation '''\n",
        "    shape = K.int_shape(input)\n",
        "    x = Conv2D(shape[3] * 1, (1, 1), strides=(1, 1), padding=\"same\",  kernel_initializer=kinit, name=name + '_conv')(input)\n",
        "    if is_batchnorm:\n",
        "        x = BatchNormalization(name=name + '_bn')(x)\n",
        "    x = Activation('relu', name = name + '_act')(x)\n",
        "    return x\n",
        "\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "kinit = 'glorot_normal'\n",
        "\n",
        "def attn_unet(lr, loss_func=None, pretrained_weights = None, input_size = (256, 256, 6)):\n",
        "        inputs = Input(shape=input_size)\n",
        "\n",
        "        #Contraction path\n",
        "        conv1 = UnetConv2D(inputs, 64, is_batchnorm=True, name='conv1')\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "        conv2 = UnetConv2D(pool1, 64, is_batchnorm=True, name='conv2')\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "        conv3 = UnetConv2D(pool2, 128, is_batchnorm=True, name='conv3')\n",
        "        conv3 = Dropout(0.1,name='drop_conv3')(conv3)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "        conv4 = UnetConv2D(pool3, 128, is_batchnorm=True, name='conv4')\n",
        "        # conv4 = Dropout(0.2, name='drop_conv4')(conv4)\n",
        "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "        conv5 = UnetConv2D(pool4, 256, is_batchnorm=True, name='conv5')\n",
        "        # conv5 = Dropout(0.2,name='drop_conv5')(conv5)\n",
        "        pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
        "\n",
        "        conv6 = UnetConv2D(pool5, 256, is_batchnorm=True, name='conv6')\n",
        "        # conv6 = Dropout(0.2, name='drop_conv6')(conv6)\n",
        "        pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
        "\n",
        "        #center layer\n",
        "        center = UnetConv2D(pool6, 512, is_batchnorm=True, name='center')\n",
        "\n",
        "        # Expansion path\n",
        "        g1 = UnetGatingSignal(center, is_batchnorm=True, name='g1')\n",
        "        attn1 = AttnGatingBlock(conv6, g1, 512, '_1')\n",
        "        # attn1 = Dropout(0.2, name='drop_attn1')(attn1)\n",
        "        convt1 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt1')(center)\n",
        "        up1 = concatenate([convt1, attn1], name='up1')\n",
        "\n",
        "        g2 = UnetGatingSignal(up1, is_batchnorm=True, name='g2')\n",
        "        attn2 = AttnGatingBlock(conv5, g2, 256, '_2')\n",
        "        # attn2 = Dropout(0.2, name='drop_attn2')(attn2)\n",
        "        convt2 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt2')(up1)\n",
        "        up2 = concatenate([convt2, attn2], name='up2')\n",
        "\n",
        "        g3 = UnetGatingSignal(up2, is_batchnorm=True, name='g3')\n",
        "        attn3 = AttnGatingBlock(conv4, g3, 128, '_3')\n",
        "        # attn3 = Dropout(0.2, name='drop_attn3')(attn3)\n",
        "        convt3 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt3')(up2)\n",
        "        up3 = concatenate([convt3, attn3], name='up3')\n",
        "\n",
        "        g4 = UnetGatingSignal(up3, is_batchnorm=True, name='g4')\n",
        "        attn4 = AttnGatingBlock(conv3, g4, 128, '_4')\n",
        "        # attn4 = Dropout(0.2, name='drop_attn4')(attn4)\n",
        "        convt4 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt4')(up3)\n",
        "        up4 = concatenate([convt4, attn4], name='up4')\n",
        "\n",
        "        g5 = UnetGatingSignal(up4, is_batchnorm=True, name='g5')\n",
        "        attn5 = AttnGatingBlock(conv2, g5, 64, '_5')\n",
        "        attn5 = Dropout(0.2, name='drop_attn5')(attn5)\n",
        "        convt5 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt5')(up4)\n",
        "        up5 = concatenate([convt5, attn5], name='up5')\n",
        "\n",
        "        convt6 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt6')(up5)\n",
        "        up6 = concatenate([convt6, conv1], name='up6')\n",
        "        conv10 = Conv2D(1, (1, 1), activation='sigmoid',  kernel_initializer=kinit, name='final')(up6)\n",
        "\n",
        "        model = Model(inputs, conv10)\n",
        "\n",
        "        # compile model\n",
        "        model.compile(optimizer = Adam(learning_rate=lr), loss = loss_func, metrics = ['accuracy', f1_m, precision_m, recall_m, dsc])\n",
        "\n",
        "        if(pretrained_weights):\n",
        "            model.load_weights(pretrained_weights)\n",
        "\n",
        "        return model\n",
        "# Compile the model\n",
        "model = attn_unet(0.001, loss_func='binary_crossentropy',input_size=(512,512,3))\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "U53nh1sKGhKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training model**"
      ],
      "metadata": {
        "id": "vjLMpm7ZC0MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# callback functions\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(f\"/content/drive/MyDrive/dl/flood/flood_best.h5\", monitor=\"val_f1_m\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', patience=5, verbose=1, mode='max')\n",
        "\n",
        "callbacks = [\n",
        "    earlyStopping,\n",
        "    checkpointer\n",
        "    ]\n",
        "\n",
        "# model training\n",
        "history = model.fit(train_dataset,epochs=50,\n",
        "                    verbose = 1,\n",
        "                    # validation_split=0.15,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# save the model weights at the end of the training process\n",
        "model.save(f\"/content/drive/MyDrive/dl/flood/flood_save.h5\")"
      ],
      "metadata": {
        "id": "948pJ2UzChTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model performance**"
      ],
      "metadata": {
        "id": "R_HcmwX3C8Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,((ax11, ax12),(ax13,ax14)) = plt.subplots(2,2,figsize=(10,10))\n",
        "ax11.plot(history.history['loss'])\n",
        "ax11.plot(history.history['val_loss'])\n",
        "ax11.title.set_text('Unet model loss')\n",
        "ax11.set_ylabel('loss')\n",
        "ax11.set_xlabel('epoch')\n",
        "ax11.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax12.plot(history.history['precision_m'])\n",
        "ax12.plot(history.history['val_precision_m'])\n",
        "ax12.set_title('Unet model precision')\n",
        "ax12.set_ylabel('precision')\n",
        "ax12.set_xlabel('epoch')\n",
        "ax12.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax13.plot(history.history['recall_m'])\n",
        "ax13.plot(history.history['val_recall_m'])\n",
        "ax13.set_title('Unet model recall')\n",
        "ax13.set_ylabel('recall')\n",
        "ax13.set_xlabel('epoch')\n",
        "ax13.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax14.plot(history.history['f1_m'])\n",
        "ax14.plot(history.history['val_f1_m'])\n",
        "ax14.set_title('Unet model f1')\n",
        "ax14.set_ylabel('f1')\n",
        "ax14.set_xlabel('epoch')\n",
        "ax14.legend(['train', 'validation'], loc='upper left')"
      ],
      "metadata": {
        "id": "YldJslxOC-Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load best model**"
      ],
      "metadata": {
        "id": "dPpLGfFHDDOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Define the custom loss function before loading the model\n",
        "custom_objects = {\"f1_m\": f1_m, 'precision_m': precision_m, 'recall_m': recall_m, 'dsc': dsc}\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/dl/flood/flood_best.h5', custom_objects=custom_objects)\n",
        "\n",
        "# pred"
      ],
      "metadata": {
        "id": "7dTQRqDrDFCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy, f1_score, precision, recall, dsc = model.evaluate(test_dataset, verbose=0)\n",
        "loss, accuracy, f1_score, precision, recall, dsc = model.evaluate(test_dataset, verbose=0)\n",
        "print(loss, accuracy, f1_score, precision, recall, dsc)"
      ],
      "metadata": {
        "id": "cJD9xmG0DHAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction on custom images**"
      ],
      "metadata": {
        "id": "z4aBNnVEDK9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "imgs = glob.glob('/content/*.jpg')\n",
        "\n",
        "img_test = np.zeros((3, 512, 512, 3))\n",
        "for index, i in enumerate(imgs):\n",
        "  img = cv2.imread(i)\n",
        "  img = cv2.resize(img, (512, 512))\n",
        "  img = img / 255.0\n",
        "  # print(img.shape)\n",
        "  img_test[index] = img"
      ],
      "metadata": {
        "id": "mpCxaXvsDMUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(img_test)\n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "pred.shape"
      ],
      "metadata": {
        "id": "KZDZiGMXDN4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(axes)= plt.subplots(3, 2, figsize=(12,12))\n",
        "\n",
        "for i in range(3):\n",
        "    # Load and display the original image\n",
        "    axes[i, 0].imshow(img_test[i])\n",
        "    axes[i, 0].set_title(f'Image {i+1}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Load and display the corresponding prediction\n",
        "    axes[i, 1].imshow(pred[i])\n",
        "    axes[i, 1].set_title(f'Prediction {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "5QrzAk_ADQl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}