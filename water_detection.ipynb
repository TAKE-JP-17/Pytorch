{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONZiuTv95sfjyol/ANyffW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAKE-JP-17/Pytorch/blob/main/water_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcm8TyL-uUIG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# precision\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "# recall\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "# f1 score\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "from tensorflow.keras.layers import UpSampling2D, multiply\n",
        "\n",
        "# 注意力門控區塊（Attention Gating Block）:\n",
        "# x：來自編碼路徑的特徵圖，通常具有較大的空間解析度。\n",
        "# g：來自解碼路徑的特徵圖，通常具有較小的空間解析度。\n",
        "# inter_shape：中間層的通道數，用於縮減特徵圖的通道數以減少計算量。\n",
        "# activation：激活函數的類型，通常為 relu。\n",
        "# name：層的名稱前綴，用於命名每個操作，以便在模型中區分不同的層。\n",
        "def AttnGatingBlock(x, g, inter_shape, activation, name):\n",
        "    ''' take g which is the spatially smaller signal, do a conv to get the same\n",
        "    number of feature channels as x (bigger spatially)\n",
        "    do a conv on x to also get same geature channels (theta_x)\n",
        "    then, upsample g to be same size as x\n",
        "    add x and g (concat_xg)\n",
        "    relu, 1x1 conv, then sigmoid then upsample the final - this gives us attn coefficients'''\n",
        "\n",
        "    shape_x = x.shape  # 32\n",
        "    shape_g = g.shape  # 16\n",
        "\n",
        "\n",
        "    # theta_x：對 x 進行卷積操作，將空間解析度縮小一半，並將通道數減少到 inter_shape。\n",
        "    # phi_g：對 g 進行1x1卷積，將其通道數減少到 inter_shape，這樣 g 和 x 的通道數相同。\n",
        "    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same', name='xl'+name)(x)  # 16\n",
        "    shape_theta_x = theta_x.shape\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)\n",
        "    # upsample_g：對 g 進行轉置卷積，將其空間解析度擴大到與 theta_x 一致。這一步是為了讓 g 和 x 在空間解析度上相匹配。\n",
        "    upsample_g = Conv2DTranspose(inter_shape, (3, 3),strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),padding='same', name='g_up'+name)(phi_g)  # 16\n",
        "\n",
        "    # concat_xg：將上採樣後的 g 和 theta_x 相加。\n",
        "    # act_xg：對相加結果應用激活函數，通常是 relu。\n",
        "    concat_xg = add([upsample_g, theta_x])\n",
        "    act_xg = Activation(activation)(concat_xg)\n",
        "    # psi：對激活後的特徵圖進行 1x1 卷積，將其通道數縮減為 1。\n",
        "    # sigmoid_xg：對 psi 的輸出進行 sigmoid 激活，生成一個權重圖（注意力係數），每個值都在 0 到 1 之間。\n",
        "    psi = Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = sigmoid_xg.shape\n",
        "\n",
        "    # upsample_psi：將注意力係數圖 sigmoid_xg 上採樣到與 x 的空間解析度相同。\n",
        "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    # Expand upsample_psi to match the number of channels in shape_x[3]/expend_as：將 upsample_psi 擴展到與 x 相同的通道數。\n",
        "    # upsample_psi = expend_as(upsample_psi, shape_x[3], name)\n",
        "\n",
        "    # Multiply with x/ y：將注意力權重圖 upsample_psi 與原始特徵圖 x 逐元素相乘，這一步突出重要的區域。\n",
        "    y = multiply([upsample_psi, x], name='q_attn' + name)\n",
        "    # result：通過 1x1 卷積將通道數恢復到與 x 相同。\n",
        "    result = Conv2D(shape_x[3], (1, 1), padding='same',name='q_attn_conv'+name)(y)\n",
        "    # result_bn：對結果進行批量正規化，以穩定訓練過程。\n",
        "    result_bn = BatchNormalization(name='q_attn_bn'+name)(result)\n",
        "    return result_bn\n",
        "\n",
        "# UnetConv2D：實現 U-Net 中的基本卷積塊，通過兩層 3x3 卷積、選擇性批量正規化和激活，提取圖像特徵。\n",
        "def UnetConv2D(input, outdim, is_batchnorm, activation, name):\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "\tif is_batchnorm:\n",
        "\t\tx =BatchNormalization(name=name + '_1_bn')(x)\n",
        "\tx = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "\tx = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "\tif is_batchnorm:\n",
        "\t\tx = BatchNormalization(name=name + '_2_bn')(x)\n",
        "\tx = Activation('relu', name=name + '_2_act')(x)\n",
        "\treturn x"
      ],
      "metadata": {
        "id": "qo8FgkVtud3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation\n",
        "\n",
        "def UnetGatingSignal(input, is_batchnorm, name):\n",
        "    ''' this is simply 1x1 convolution, bn, activation '''\n",
        "    shape = input.shape\n",
        "    x = Conv2D(shape[3] * 1, (1, 1), strides=(1, 1), padding=\"same\",  kernel_initializer=kinit, name=name + '_conv')(input)\n",
        "    if is_batchnorm:\n",
        "        x = BatchNormalization(name=name + '_bn')(x)\n",
        "    x = Activation('relu', name = name + '_act')(x)\n",
        "    return x\n",
        "\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code  # 設置 TensorFlow 的維度順序\n",
        "kinit = 'glorot_normal' # # 權重初始化方法\n",
        "\n",
        "def attn_unet(lr, loss_func=None, pretrained_weights=None,input_size = (256,256,3)):\n",
        "    inputs = Input(shape=input_size)\n",
        "\n",
        "    conv1 = UnetConv2D(inputs, 32, is_batchnorm=True, activation='relu', name='conv1')\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = UnetConv2D(pool1, 64, is_batchnorm=True, activation='relu', name='conv2')\n",
        "    conv2 = Dropout(0.1,name='drop_conv3')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    center = UnetConv2D(pool2,128,is_batchnorm=True, activation='relu', name='center')\n",
        "\n",
        "    # Expansion path\n",
        "    g1 = UnetGatingSignal(center, is_batchnorm=True, name='g1')\n",
        "    attn1 = AttnGatingBlock(conv2, g1, 128, activation='relu', name='_1')\n",
        "    # attn1 = Dropout(0.2, name='drop_attn1')(attn1)\n",
        "    convt1 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt1')(center)\n",
        "    up1 = concatenate([convt1, attn1], name='up1')\n",
        "\n",
        "    convt2= Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu', kernel_initializer=kinit, name='convt2')(up1)\n",
        "    up2 = concatenate([convt2, conv1], name='up2')\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid',  kernel_initializer=kinit, name='final')(up2)\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer = Adam(learning_rate=lr), loss = loss_func, metrics = ['accuracy', f1_m, precision_m, recall_m, dsc])\n",
        "\n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = attn_unet(0.001, loss_func='binary_crossentropy', input_size=(256,256,3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1ncSTfGHuiyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# 訓練資料夾路徑\n",
        "original_train_dir = 'C:/Users/User/gary/wd_data_t2/train'\n",
        "augmented_train_dir = 'C:/Users/User/gary/wd_data_t2/new_train'\n",
        "val_dir = 'C:/Users/User/gary/wd_data_t2/val'\n",
        "\n",
        "# 創建新的資料夾結構\n",
        "os.makedirs(os.path.join(augmented_train_dir, 'Image'), exist_ok=True)\n",
        "os.makedirs(os.path.join(augmented_train_dir, 'Label'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'Image'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'Label'), exist_ok=True)\n",
        "\n",
        "# **步驟 1：分割資料集**\n",
        "def split_dataset(train_dir, val_dir, val_ratio=0.1):\n",
        "    \"\"\"\n",
        "    分割訓練資料集，將一部分數據移到驗證資料夾中。\n",
        "    \"\"\"\n",
        "    image_dir = os.path.join(train_dir, 'Image')\n",
        "    label_dir = os.path.join(train_dir, 'Label')\n",
        "\n",
        "    image_files = sorted(os.listdir(image_dir))\n",
        "    label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    # 將影像與標籤根據名稱中的編號對應\n",
        "    image_dict = {img.replace('image_tile_', ''): img for img in image_files}\n",
        "    label_dict = {lbl.replace('label_tile_', ''): lbl for lbl in label_files}\n",
        "\n",
        "    common_keys = set(image_dict.keys()) & set(label_dict.keys())\n",
        "    assert len(common_keys) > 0, \"無法找到影像與標籤的匹配項！\"\n",
        "\n",
        "    paired_files = [(image_dict[key], label_dict[key]) for key in common_keys]\n",
        "\n",
        "    # 隨機選擇驗證集索引\n",
        "    val_size = int(len(paired_files) * val_ratio)\n",
        "    val_indices = random.sample(range(len(paired_files)), val_size)\n",
        "\n",
        "    for idx, (image_file, label_file) in enumerate(paired_files):\n",
        "        src_image_path = os.path.join(image_dir, image_file)\n",
        "        src_label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        if idx in val_indices:\n",
        "            shutil.copy(src_image_path, os.path.join(val_dir, 'Image', image_file))\n",
        "            shutil.copy(src_label_path, os.path.join(val_dir, 'Label', label_file))\n",
        "        else:\n",
        "            shutil.copy(src_image_path, os.path.join(augmented_train_dir, 'Image', image_file))\n",
        "            shutil.copy(src_label_path, os.path.join(augmented_train_dir, 'Label', label_file))\n",
        "\n",
        "    print(f\"分割完成：訓練集 {len(paired_files) - val_size} 個，驗證集 {val_size} 個。\")\n",
        "\n",
        "\n",
        "\n",
        "# **步驟 2：資料增強**\n",
        "def augment_image_and_label(image, label, augmentations):\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    # 隨機旋轉\n",
        "    if 'rotation_range' in augmentations:\n",
        "        angle = np.random.uniform(-augmentations['rotation_range'], augmentations['rotation_range'])\n",
        "        M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1)\n",
        "        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
        "        label = cv2.warpAffine(label.squeeze(), M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT)\n",
        "        label = label[..., None]  # 保證單通道\n",
        "\n",
        "    # 隨機平移\n",
        "    if 'width_shift_range' in augmentations or 'height_shift_range' in augmentations:\n",
        "        max_dx = int(augmentations.get('width_shift_range', 0) * w)\n",
        "        max_dy = int(augmentations.get('height_shift_range', 0) * h)\n",
        "        dx = np.random.randint(-max_dx, max_dx + 1)\n",
        "        dy = np.random.randint(-max_dy, max_dy + 1)\n",
        "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
        "        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
        "        label = cv2.warpAffine(label.squeeze(), M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT)\n",
        "        label = label[..., None]\n",
        "\n",
        "    # 隨機縮放\n",
        "    if 'zoom_range' in augmentations:\n",
        "        zoom = np.random.uniform(1 - augmentations['zoom_range'], 1 + augmentations['zoom_range'])\n",
        "        new_w, new_h = int(w * zoom), int(h * zoom)\n",
        "        image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "        label = cv2.resize(label.squeeze(), (new_w, new_h), interpolation=cv2.INTER_NEAREST)[..., None]\n",
        "\n",
        "        if zoom > 1:  # 裁切\n",
        "            start_x = (new_w - w) // 2\n",
        "            start_y = (new_h - h) // 2\n",
        "            image = image[start_y:start_y + h, start_x:start_x + w]\n",
        "            label = label[start_y:start_y + h, start_x:start_x + w]\n",
        "        else:  # 填充\n",
        "            pad_x = (w - new_w) // 2\n",
        "            pad_y = (h - new_h) // 2\n",
        "            image = cv2.copyMakeBorder(image, pad_y, pad_y, pad_x, pad_x, cv2.BORDER_REFLECT)\n",
        "            label = cv2.copyMakeBorder(label, pad_y, pad_y, pad_x, pad_x, cv2.BORDER_REFLECT)\n",
        "\n",
        "    # 隨機水平翻轉\n",
        "    if augmentations.get('horizontal_flip', False) and np.random.rand() > 0.5:\n",
        "        image = cv2.flip(image, 1)\n",
        "        label = cv2.flip(label, 1)\n",
        "\n",
        "    # 隨機垂直翻轉\n",
        "    if augmentations.get('vertical_flip', False) and np.random.rand() > 0.5:\n",
        "        image = cv2.flip(image, 0)\n",
        "        label = cv2.flip(label, 0)\n",
        "\n",
        "    # 確保標籤影像為單通道\n",
        "    label = label.squeeze()[..., None]  # 維持單通道結構\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def augment_data(data_dir, augmentations, target_size=None, augment_count=5):\n",
        "    \"\"\"\n",
        "    資料增強函數，對影像和標籤進行同步增強。\n",
        "    \"\"\"\n",
        "    image_dir = os.path.join(data_dir, 'Image')\n",
        "    label_dir = os.path.join(data_dir, 'Label')\n",
        "    image_files = sorted(os.listdir(image_dir))\n",
        "    label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    for image_file, label_file in zip(image_files, label_files):\n",
        "        with rasterio.open(os.path.join(image_dir, image_file)) as src:\n",
        "            img = src.read()\n",
        "            img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "        with rasterio.open(os.path.join(label_dir, label_file)) as src:\n",
        "            lbl = src.read(1)[..., None]  # 確保標籤讀取為單通道\n",
        "\n",
        "        if target_size:\n",
        "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "            lbl = cv2.resize(lbl.squeeze(), target_size, interpolation=cv2.INTER_NEAREST)[..., None]\n",
        "\n",
        "        for i in range(augment_count):\n",
        "            aug_img, aug_lbl = augment_image_and_label(img, lbl, augmentations)\n",
        "\n",
        "            # 儲存增強後的影像和標籤\n",
        "            output_image_path = os.path.join(image_dir, f\"{image_file.replace('.tif', '')}_aug_{i}.tif\")\n",
        "            output_label_path = os.path.join(label_dir, f\"{label_file.replace('.tif', '')}_aug_{i}.tif\")\n",
        "\n",
        "            with rasterio.open(output_image_path, 'w', driver='GTiff',\n",
        "                               height=aug_img.shape[0], width=aug_img.shape[1],\n",
        "                               count=aug_img.shape[2], dtype=aug_img.dtype) as dst:\n",
        "                dst.write(np.transpose(aug_img, (2, 0, 1)))\n",
        "\n",
        "            with rasterio.open(output_label_path, 'w', driver='GTiff',\n",
        "                               height=aug_lbl.shape[0], width=aug_lbl.shape[1],\n",
        "                               count=1,  # 強制單通道\n",
        "                               dtype=aug_lbl.dtype) as dst:\n",
        "                dst.write(aug_lbl.squeeze(), 1)\n",
        "\n",
        "\n",
        "    print(\"資料增強完成！\")\n",
        "\n",
        "\n",
        "# 分割資料集並進行增強\n",
        "split_dataset(original_train_dir, val_dir)\n",
        "augmentations = {\n",
        "    'rotation_range': 30,\n",
        "    'width_shift_range': 0.2,\n",
        "    'height_shift_range': 0.2,\n",
        "    'shear_range': 0.2,\n",
        "    'zoom_range': 0.2,\n",
        "    'horizontal_flip': True,\n",
        "    'vertical_flip': True,\n",
        "    'fill_mode': 'reflect'\n",
        "}\n",
        "augment_data(augmented_train_dir, augmentations, augment_count=5)\n",
        "\n",
        "# **步驟 3：定義數據生成器**\n",
        "def data_generator_from_dir(data_dir, batch_size):\n",
        "    image_dir = os.path.join(data_dir, 'Image')\n",
        "    label_dir = os.path.join(data_dir, 'Label')\n",
        "\n",
        "    image_files = sorted(os.listdir(image_dir))\n",
        "    label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    while True:\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_image_files = image_files[i:i + batch_size]\n",
        "            batch_label_files = label_files[i:i + batch_size]\n",
        "\n",
        "            images = []\n",
        "            labels = []\n",
        "\n",
        "            for img_file, label_file in zip(batch_image_files, batch_label_files):\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "                label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "                with rasterio.open(img_path) as src:\n",
        "                    img = src.read()\n",
        "                    img = np.transpose(img, (1, 2, 0))\n",
        "                    img_min, img_max = img.min(), img.max()\n",
        "                    if img_max > img_min:\n",
        "                        img = (img - img_min) / (img_max - img_min)\n",
        "                    else:\n",
        "                        img = np.zeros_like(img)\n",
        "                    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                with rasterio.open(label_path) as src:\n",
        "                    label = src.read(1)  # 僅讀取第一個通道\n",
        "                    label = cv2.resize(label, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "                    label = label[..., None]/255  # 保持單通道結構\n",
        "\n",
        "                images.append(img.astype(np.float32))\n",
        "                labels.append(label.astype(np.float32))\n",
        "\n",
        "\n",
        "            images = np.array(images, dtype=np.float32)\n",
        "            labels = np.array(labels, dtype=np.float32)\n",
        "            #print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "            yield (images, labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 訓練和驗證資料生成器\n",
        "batch_size = 4\n",
        "train_generator = data_generator_from_dir(augmented_train_dir, batch_size=batch_size)\n",
        "val_generator = data_generator_from_dir(val_dir, batch_size=batch_size)\n",
        "sample_batch = next(train_generator)\n",
        "print(f\"Sample batch images shape: {sample_batch[0].shape}\")\n",
        "print(f\"Sample batch labels shape: {sample_batch[1].shape}\")\n",
        "\n",
        "\n",
        "steps_per_epoch = len(os.listdir(os.path.join(augmented_train_dir, 'Image'))) // batch_size\n",
        "validation_steps = len(os.listdir(os.path.join(val_dir, 'Image'))) // batch_size\n",
        "\n",
        "# 設置檢查點回調\n",
        "checkpoint = ModelCheckpoint('C:/Users/User/gary/space/01_model/wd_t2_e50_att_unet_model_checkpoint.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# **步驟 4：繪製訓練曲線**\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], 'bo-', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YALMnW9wumPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "import rasterio\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
        "\n",
        "# 定義批次加載數據生成器\n",
        "def data_generator_from_dir(data_dir, batch_size):\n",
        "    image_dir = os.path.join(data_dir, 'Image')\n",
        "    label_dir = os.path.join(data_dir, 'Label')\n",
        "\n",
        "    image_files = sorted(os.listdir(image_dir))\n",
        "    label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    while True:\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_image_files = image_files[i:i + batch_size]\n",
        "            batch_label_files = label_files[i:i + batch_size]\n",
        "\n",
        "            images = []\n",
        "            labels = []\n",
        "\n",
        "            for img_file, label_file in zip(batch_image_files, batch_label_files):\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "                label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "                with rasterio.open(img_path) as src:\n",
        "                    img = src.read()\n",
        "                    img = np.transpose(img, (1, 2, 0))\n",
        "                    img_min, img_max = img.min(), img.max()\n",
        "                    if img_max > img_min:\n",
        "                        img = (img - img_min) / (img_max - img_min)\n",
        "                    else:\n",
        "                        img = np.zeros_like(img)\n",
        "                    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                with rasterio.open(label_path) as src:\n",
        "                    label = src.read(1)  # 僅讀取第一個通道\n",
        "                    label = cv2.resize(label, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "                    label = label[..., None]/255  # 保持單通道結構\n",
        "\n",
        "                images.append(img.astype(np.float32))\n",
        "                labels.append(label.astype(np.float32))\n",
        "\n",
        "\n",
        "            images = np.array(images, dtype=np.float32)\n",
        "            labels = np.array(labels, dtype=np.float32)\n",
        "            #print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "            yield (images, labels)\n",
        "\n",
        "# 訓練和驗證資料生成器\n",
        "batch_size = 8\n",
        "train_data_dir = 'C:/Users/User/gary/wd_data_t2/new_train'\n",
        "val_data_dir = 'C:/Users/User/gary/wd_data_t2/val'\n",
        "test_data_dir = 'C:/Users/User/gary/wd_data_t2/test'\n",
        "\n",
        "train_generator = data_generator_from_dir(train_data_dir, batch_size=batch_size)\n",
        "val_generator = data_generator_from_dir(val_data_dir, batch_size=batch_size)\n",
        "test_generator = data_generator_from_dir(test_data_dir, batch_size=batch_size)\n",
        "\n",
        "# 定義儲存影像的函數\n",
        "def save_sample(X, label, pred_label, index, folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 儲存影像與標籤\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
        "\n",
        "    # 提取影像\n",
        "    image = X[0]  # 3通道的 RGB 影像\n",
        "\n",
        "    # 顯示 RGB 影像\n",
        "    axes[0].imshow(image)  # 正常顯示 RGB 圖像\n",
        "    axes[0].set_title('RGB Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # 顯示真實標籤 (單通道)\n",
        "    axes[1].imshow(label[0, :, :, 0], cmap='gray')\n",
        "    axes[1].set_title('Ground Truth Label')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # 顯示預測標籤 (經過閥值處理)\n",
        "    axes[2].imshow(pred_label[0, :, :, 0], cmap='gray')\n",
        "    axes[2].set_title('Predicted Label (Thresholded)')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    # 計算評估指標\n",
        "    label_flat = label[0, :, :, 0].flatten()\n",
        "    pred_flat = pred_label[0, :, :, 0].flatten()\n",
        "\n",
        "    # 檢查全零情況\n",
        "    if np.sum(label_flat) == 0 and np.sum(pred_flat) == 0:\n",
        "        accuracy, precision, recall, f1 = 1.0, 1.0, 1.0, 1.0\n",
        "    else:\n",
        "        accuracy = accuracy_score(label_flat, pred_flat)\n",
        "        precision = precision_score(label_flat, pred_flat, zero_division=1)\n",
        "        recall = recall_score(label_flat, pred_flat, zero_division=1)\n",
        "        f1 = f1_score(label_flat, pred_flat, zero_division=1)\n",
        "\n",
        "\n",
        "    # 在圖表上顯示評估指標\n",
        "    fig.suptitle(\n",
        "        f'Accuracy: {accuracy:.4f}\\n'\n",
        "        f'Precision: {precision:.4f}\\n'\n",
        "        f'Recall: {recall:.4f}\\n'\n",
        "        f'F1 Score: {f1:.4f}\\n',\n",
        "        #f'Kappa: {kappa:.4f}',\n",
        "        fontsize=16\n",
        "    )\n",
        "\n",
        "    # 儲存影像\n",
        "    plt.savefig(os.path.join(folder_path, f'sample_{index}.png'))\n",
        "    plt.close()  # 關閉圖表，釋放內存\n",
        "# 使用批次進行預測和儲存結果\n",
        "def save_results_in_batches(generator, dataset_name, folder_path, total_images, batch_size=8, threshold=0.5):\n",
        "    print(f'\\nSaving results for {dataset_name}...')\n",
        "\n",
        "    # 計數器\n",
        "    index = 0\n",
        "\n",
        "    for X_batch, label_batch in generator:\n",
        "        # 預測模型輸出\n",
        "        pred_label_batch = model.predict(X_batch)\n",
        "\n",
        "        # 對預測結果進行閥值處理（二元化）\n",
        "        pred_label_batch = (pred_label_batch >= threshold).astype(np.uint8)\n",
        "\n",
        "        # 儲存每一批次的結果\n",
        "        for j in range(len(X_batch)):\n",
        "            if index >= total_images:  # 停止條件，避免超過總影像數量\n",
        "                print(f\"Reached total of {total_images} images, stopping...\")\n",
        "                return\n",
        "\n",
        "            save_sample(X_batch[j:j+1], label_batch[j:j+1],\n",
        "                        pred_label_batch[j:j+1],\n",
        "                        index=index, folder_path=folder_path)\n",
        "            index += 1\n",
        "\n",
        "\n",
        "# 加載已訓練好的模型\n",
        "model = load_model('C:/Users/User/gary/space/01_model/wd_t2_e50_att_unet_model_checkpoint.keras', compile=False)\n",
        "\n",
        "# 設定步數，根據資料數量和批次大小計算\n",
        "steps_per_epoch = len(os.listdir(os.path.join(train_data_dir, 'Image'))) // batch_size\n",
        "validation_steps = len(os.listdir(os.path.join(val_data_dir, 'Image'))) // batch_size\n",
        "\n",
        "# 計算訓練集總影像數量\n",
        "total_train_images = len(os.listdir(os.path.join(train_data_dir, 'Image')))\n",
        "\n",
        "# 儲存訓練集結果\n",
        "save_results_in_batches(train_generator, 'Training Set', 'C:/Users/User/gary/space/model/01result/02_test2_e50/02_t2_e50_training_results', total_images=total_train_images, batch_size=batch_size)\n",
        "\n",
        "# 計算驗證集總影像數量\n",
        "#total_val_images = len(os.listdir(os.path.join(val_data_dir, 'Image')))\n",
        "\n",
        "# 儲存驗證集結果\n",
        "#save_results_in_batches(val_generator, 'Validation Set', 'C:/Users/User/gary/space/model/01result/02_test2_e50/02_t2_e50_validation_results', total_images=total_val_images, batch_size=batch_size)\n",
        "\n",
        "# 計算測試集總影像數量\n",
        "#total_test_images = len(os.listdir(os.path.join(test_data_dir, 'Image')))\n",
        "\n",
        "# 儲存測試集結果\n",
        "#save_results_in_batches(test_generator, 'Test Set', 'C:/Users/User/gary/space/model/01result/02_test2_e50/02_t2_e50_test_results', total_images=total_test_images, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "J_cI1M1WuuyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}