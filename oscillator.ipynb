{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8z+dWV/iCHnb6WO1RvPea",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAKE-JP-17/Pytorch/blob/main/oscillator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIkhMpIdu8e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exact_solution(d, w0, t):\n",
        "  \"Define the analytical solution to the under-damped harmonic oscillator problem above.\"\n",
        "  assert d < w0\n",
        "  w = np.sqrt(w0**2-d**2)\n",
        "  phi = np.arctan(-d/w)\n",
        "  A = 1/(2*np.cos(phi))\n",
        "  cos = torch.cos(phi+w*t)\n",
        "  exp = torch.exp(-d*t)\n",
        "  u = exp*2*A*cos\n",
        "  return u\n",
        "\n",
        "class FCN(nn.Module):\n",
        "  \"Define a standard fully-connected network in PyTorch\"\n",
        "\n",
        "  def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "    super().__init__()\n",
        "    activation = nn.Tanh\n",
        "    self.fcs = nn.Sequential(*[\n",
        "             nn.Linear(N_INPUT, N_HIDDEN),\n",
        "             activation()])\n",
        "    self.fch = nn.Sequential(*[\n",
        "             nn.Sequential(*[\n",
        "                nn.Linear(N_HIDDEN, N_HIDDEN),\n",
        "                activation()]) for _ in range(N_LAYERS-1)])\n",
        "    self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fcs(x)\n",
        "    x = self.fch(x)\n",
        "    x = self.fce(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "CzZjSPOL6v9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function"
      ],
      "metadata": {
        "id": "D9F5xDDbFYH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# define a neural network to train\n",
        "# TODO: write code here\n",
        "pinn = FCN(1,1,32,3)\n",
        "\n",
        "# define boundary points, for the boundary loss\n",
        "# TODO: write code here\n",
        "t_boundary = torch.tensor(0.).view(-1,1).requires_grad_(True)\n",
        "\n",
        "# define training points over the entire domain, for the physics loss\n",
        "# TODO: write code here\n",
        "t_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)\n",
        "\n",
        "# train the PINN\n",
        "D, w0 = 2, 20\n",
        "mu, k = 2*d, w0**2\n",
        "t_test = torch.linspace(0,1,300).view(-1,1)\n",
        "u_exact = exact_solution(d, w0, t_test)\n",
        "optimizer = torch.optim.Adam(pinn.parameters(), lr=1e-3)\n",
        "for i in range(15001):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # compute each term of the PINN loss function above\n",
        "  # using the following hyperparameters:\n",
        "  lambda1, lambda2 = 1e-1, 1e-4\n",
        "\n",
        "  # compute boundary loss\n",
        "  # TODO: write code here\n",
        "  u = pinn(t_boundary) # (1,1)\n",
        "  loss1 = (torch.squeeze(u) - 1)**2\n",
        "\n",
        "  dudt = torch.autograd.grad(u, t_boundary, torch.ones_like(u), create_graph=True)[0]\n",
        "  loss2 = (torch.squeeze(dudt) - 0)**2\n",
        "\n",
        "  # compute physics loss\n",
        "  # TODO: write code here\n",
        "  u = pinn(t_physics)\n",
        "  dudt = torch.autograd.grad(u, t_physics, torch.ones_like(u), create_graph=True)[0]\n",
        "  d2udt2 = torch.autograd.grad(dudt, t_physics, torch.ones_like(dudt), create_graph=True)[0]\n",
        "  loss3 = torch.mean((d2udt2 + mu*dudt + k*u)**2)\n",
        "\n",
        "  # backpropagate joint loss, take optimizer step\n",
        "  # TODO: write code here\n",
        "  loss = loss1 + lambda1*loss2 + lambda2*loss3\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # plot the result as training progresses\n",
        "  if i % 5000 == 0:\n",
        "    #print(u.abs().mean().item(), dudt.abs().mean().item(), d2udt2.abs().mean().item())\n",
        "    u = pinn(t_test).detach()\n",
        "    plt.figure(figsize=(6,2.5))\n",
        "    plt.scatter(t_physics.detach()[:,0],\n",
        "                torch.zeros_like(t_physics)[:,0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
        "    plt.scatter(t_boundary.detach()[:,0],\n",
        "                torch.zeros_like(t_boundary)[:,0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
        "    plt.plot(t_test[:,0], u_exact[:,0], label=\"Exact Solution\", color=\"tab:grey\", alpha=0.6)\n",
        "    plt.plot(t_test[:,0], u[:,0], label=\"PINN Solution\", color=\"tab:green\")\n",
        "    plt.title(f\"Training step {i}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2-A-qF-kExUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWAGRGtcExTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}